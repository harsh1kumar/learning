{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b80806-702f-463f-be82-80a650f46fdb",
   "metadata": {},
   "source": [
    "# Optimizers in PyTorch\n",
    "\n",
    "Data used for this notebook is from a Kaggle competition  \n",
    "Link to the competition: https://www.kaggle.com/c/santander-customer-transaction-prediction  \n",
    "Type of Problem: Classification  \n",
    "  \n",
    "  \n",
    "Pytorch Optimizers: https://pytorch.org/docs/stable/optim.html#algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6036b3-c176-45a4-82e2-05c48c59de55",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a2be68-51fc-4c0f-a946-b90c614f7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42486aec-1a7a-4049-8321-925fba6c8733",
   "metadata": {},
   "source": [
    "## Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c15e93-a26a-4631-8678-5b56f4f9eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 202)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.093</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.389</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2  var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.093  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.389  12.3622  7.0433  5.6208   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "\n",
       "[2 rows x 202 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e519dd-9e8b-432d-9079-2b55156d001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d1975-83c4-489f-a8d2-2c0f7afc6fce",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b88cbe2-de8d-4808-8dff-e87d8ec26f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_columns = [c for c in df_train.columns if c not in ('ID_code','target')]\n",
    "len(var_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37d69e3-0eae-4640-b065-b2718a097ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>0.515985</td>\n",
       "      <td>0.527761</td>\n",
       "      <td>0.498848</td>\n",
       "      <td>0.516818</td>\n",
       "      <td>0.517698</td>\n",
       "      <td>0.551997</td>\n",
       "      <td>0.501877</td>\n",
       "      <td>0.501123</td>\n",
       "      <td>0.522330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532601</td>\n",
       "      <td>0.521950</td>\n",
       "      <td>0.470032</td>\n",
       "      <td>0.502746</td>\n",
       "      <td>0.483477</td>\n",
       "      <td>0.536917</td>\n",
       "      <td>0.507605</td>\n",
       "      <td>0.488022</td>\n",
       "      <td>0.483899</td>\n",
       "      <td>0.527460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>0.152716</td>\n",
       "      <td>0.159324</td>\n",
       "      <td>0.153221</td>\n",
       "      <td>0.154463</td>\n",
       "      <td>0.139968</td>\n",
       "      <td>0.157852</td>\n",
       "      <td>0.142057</td>\n",
       "      <td>0.152988</td>\n",
       "      <td>0.161333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140158</td>\n",
       "      <td>0.155773</td>\n",
       "      <td>0.121015</td>\n",
       "      <td>0.132779</td>\n",
       "      <td>0.162998</td>\n",
       "      <td>0.149925</td>\n",
       "      <td>0.167666</td>\n",
       "      <td>0.152592</td>\n",
       "      <td>0.152223</td>\n",
       "      <td>0.154974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404160</td>\n",
       "      <td>0.405322</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>0.400217</td>\n",
       "      <td>0.414637</td>\n",
       "      <td>0.428839</td>\n",
       "      <td>0.396761</td>\n",
       "      <td>0.384659</td>\n",
       "      <td>0.396368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431376</td>\n",
       "      <td>0.404422</td>\n",
       "      <td>0.385063</td>\n",
       "      <td>0.411373</td>\n",
       "      <td>0.360573</td>\n",
       "      <td>0.429027</td>\n",
       "      <td>0.376952</td>\n",
       "      <td>0.379516</td>\n",
       "      <td>0.380712</td>\n",
       "      <td>0.410436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508191</td>\n",
       "      <td>0.528530</td>\n",
       "      <td>0.491004</td>\n",
       "      <td>0.518970</td>\n",
       "      <td>0.520277</td>\n",
       "      <td>0.556658</td>\n",
       "      <td>0.497967</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.527633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531653</td>\n",
       "      <td>0.517279</td>\n",
       "      <td>0.467860</td>\n",
       "      <td>0.504894</td>\n",
       "      <td>0.481614</td>\n",
       "      <td>0.533706</td>\n",
       "      <td>0.510850</td>\n",
       "      <td>0.484718</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.534987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620387</td>\n",
       "      <td>0.645236</td>\n",
       "      <td>0.603369</td>\n",
       "      <td>0.632294</td>\n",
       "      <td>0.619692</td>\n",
       "      <td>0.672246</td>\n",
       "      <td>0.599256</td>\n",
       "      <td>0.615573</td>\n",
       "      <td>0.650798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630091</td>\n",
       "      <td>0.628818</td>\n",
       "      <td>0.553659</td>\n",
       "      <td>0.598340</td>\n",
       "      <td>0.608396</td>\n",
       "      <td>0.638836</td>\n",
       "      <td>0.638353</td>\n",
       "      <td>0.601460</td>\n",
       "      <td>0.594820</td>\n",
       "      <td>0.648661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490       0.515985       0.527761       0.498848   \n",
       "std         0.300653       0.152716       0.159324       0.153221   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.404160       0.405322       0.383234   \n",
       "50%         0.000000       0.508191       0.528530       0.491004   \n",
       "75%         0.000000       0.620387       0.645236       0.603369   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.516818       0.517698       0.551997       0.501877   \n",
       "std         0.154463       0.139968       0.157852       0.142057   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.400217       0.414637       0.428839       0.396761   \n",
       "50%         0.518970       0.520277       0.556658       0.497967   \n",
       "75%         0.632294       0.619692       0.672246       0.599256   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean        0.501123       0.522330  ...       0.532601       0.521950   \n",
       "std         0.152988       0.161333  ...       0.140158       0.155773   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.384659       0.396368  ...       0.431376       0.404422   \n",
       "50%         0.497138       0.527633  ...       0.531653       0.517279   \n",
       "75%         0.615573       0.650798  ...       0.630091       0.628818   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.470032       0.502746       0.483477       0.536917   \n",
       "std         0.121015       0.132779       0.162998       0.149925   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.385063       0.411373       0.360573       0.429027   \n",
       "50%         0.467860       0.504894       0.481614       0.533706   \n",
       "75%         0.553659       0.598340       0.608396       0.638836   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        0.507605       0.488022       0.483899       0.527460  \n",
       "std         0.167666       0.152592       0.152223       0.154974  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.376952       0.379516       0.380712       0.410436  \n",
       "50%         0.510850       0.484718       0.487100       0.534987  \n",
       "75%         0.638353       0.601460       0.594820       0.648661  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_train[var_columns] = scaler.fit_transform(df_train[var_columns])\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d149ff-afbe-48db-b8ca-e66ab168014c",
   "metadata": {},
   "source": [
    "Split training data into dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26f0391-2a89-4e55-b489-00bf44cca761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = df_train.loc[:, var_columns].to_numpy()\n",
    "y_np = df_train.loc[:, 'target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912841b7-b056-4932-89ed-1df681b119d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba1a41c-64ec-4fbe-b734-0981d29fd13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([160000, 200]),\n",
       " torch.Size([40000, 200]),\n",
       " torch.Size([160000, 1]),\n",
       " torch.Size([40000, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d8c88-3807-470f-812f-4cd56fee4231",
   "metadata": {},
   "source": [
    "## Training for multiple epochs, with optimizer passed as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32efd667-128b-4a82-b297-517c7c35075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, batch_size, X_train, y_train, X_val, y_val):\n",
    "    loss_fn = nn.BCELoss()\n",
    "    \n",
    "    loss_train_list=[]\n",
    "    loss_val_list=[]\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for b in range(0, X_train.shape[0], batch_size):\n",
    "            \n",
    "            # Get data in batches\n",
    "            X_train_batch = X_train[b:b+batch_size]\n",
    "            y_train_batch = y_train[b:b+batch_size]\n",
    "\n",
    "            # Make predictions\n",
    "            y_train_batch_pred = model(X_train_batch)\n",
    "            y_val_pred = model(X_val)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss_train = loss_fn(y_train_batch_pred, y_train_batch)\n",
    "            loss_val = loss_fn(y_val_pred, y_val)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_train_list.append(loss_train.item())\n",
    "        loss_val_list.append(loss_val.item())\n",
    "        print(f'Epoch {epoch}, training loss {loss_train}, validation loss {loss_val}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c5b13-39cf-4043-b15c-da625434a35a",
   "metadata": {},
   "source": [
    "#### Calculate ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e8ce806-7039-4509-a279-e5ab7731fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_auc(model, X_val, y_val):\n",
    "    y_val_pred = model(X_val)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_val.detach().numpy(), y_val_pred.detach().numpy())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a8af8-6fb9-403a-86e2-2381046f114f",
   "metadata": {},
   "source": [
    "## 1. Stochastic Gradient Descent (SGD)\n",
    "\n",
    "SGD updates model parameters using the gradient of the loss with respect to a single training example  \n",
    "\n",
    "Cons:\n",
    "- Prone to oscillations\n",
    "- May have slow convergence on ill-conditioned surfaces  \n",
    "\n",
    "[Pytorch documentation](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "124acd25-26be-4eb9-9bdf-2efc2105fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Linear(200, 1),\n",
    "        nn.Sigmoid()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "978aee72-6804-43a6-b62a-ca878980062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "batch_size = 1\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a11a591-4cc2-488c-8d91-e95779372b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.0046682702377438545, validation loss 0.39241695404052734\n",
      "Epoch 1, training loss 0.0026896006893366575, validation loss 0.4162083566188812\n",
      "Epoch 2, training loss 0.0025220222305506468, validation loss 0.4160119593143463\n",
      "\n",
      "ROC AUC: 0.8382488823127425\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    optimizer,\n",
    "                    batch_size,\n",
    "                    X_train[:10000],\n",
    "                    y_train[:10000],\n",
    "                    X_val,\n",
    "                    y_val)\n",
    "\n",
    "roc_auc = validation_auc(model, X_val, y_val)\n",
    "print(f\"\\nROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1731a68-26de-40c0-8c00-fb2337f580f8",
   "metadata": {},
   "source": [
    "## 2. Mini-Batch SGD\n",
    "\n",
    "Mini-batch GD is a compromise between SGD and GD, where updates are performed on small batches of data  \n",
    "\n",
    "Pros:\n",
    "- Efficient and suitable for datasets that do not fit into memory  \n",
    "\n",
    "Cons:\n",
    "- Requires tuning of the mini-batch size\n",
    "- Convergence path may still oscillate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7863a0ce-b355-461d-9e1b-fda8797f1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Linear(200, 1),\n",
    "        nn.Sigmoid()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4704fb7-fd7b-47d3-8be9-bb87f8df890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "batch_size = 1000\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f2d30a4-d37b-4c40-9b92-9f3aa7170fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.26435109972953796, validation loss 0.3238053023815155\n",
      "Epoch 1, training loss 0.25916793942451477, validation loss 0.3175814747810364\n",
      "Epoch 2, training loss 0.2543502151966095, validation loss 0.3118334114551544\n",
      "\n",
      "ROC AUC: 0.8172759867152424\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    optimizer,\n",
    "                    batch_size,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_val,\n",
    "                    y_val)\n",
    "\n",
    "roc_auc = validation_auc(model, X_val, y_val)\n",
    "print(f\"\\nROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14ae35-84e7-4483-b022-b3e57bc9c7b6",
   "metadata": {},
   "source": [
    "## 3. SGD with Momentum\n",
    "\n",
    "Momentum helps accelerate SGD in the relevant direction by adding a fraction of the previous update to the current update  \n",
    "\n",
    "Pros:\n",
    "- Accelerates convergence, particularly in the presence of high curvature, small but consistent gradients, or noisy data  \n",
    "\n",
    "Cons:\n",
    "- May overshoot the minimum\n",
    "- Sensitive to the choice of the momentum parameter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ce46fe-5776-4067-a7c6-ac8115b656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(200, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40259f4e-f31d-4992-8f3d-8b5ebfb3a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.5)\n",
    "batch_size = 1\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af47dc65-221a-46e7-a0ed-343cfbfd3296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.00012786472507286817, validation loss 0.6385082602500916\n",
      "Epoch 1, training loss 0.00024983016191981733, validation loss 0.5454624891281128\n",
      "Epoch 2, training loss 0.0002267108648084104, validation loss 0.5533403754234314\n",
      "\n",
      "ROC AUC: 0.8347724832383537\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    optimizer,\n",
    "                    batch_size,\n",
    "                    X_train[:10000],\n",
    "                    y_train[:10000],\n",
    "                    X_val,\n",
    "                    y_val)\n",
    "\n",
    "roc_auc = validation_auc(model, X_val, y_val)\n",
    "print(f\"\\nROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b5971-75a8-4867-9d26-940e6c4d139a",
   "metadata": {},
   "source": [
    "## 4. Adagrad\n",
    "\n",
    "Adagrad adapts learning rates for each parameter by scaling them inversely proportional to the square root of the sum of historical squared gradients  \n",
    "\n",
    "Pros:\n",
    "- Well-suited for sparse data  \n",
    "\n",
    "Cons:\n",
    "- Learning rates can become too small, leading to slow convergence\n",
    "- Accumulates squared gradients, causing the learning rate to decay over time  \n",
    "\n",
    "\n",
    "[pytorch documentation](https://pytorch.org/docs/stable/generated/torch.optim.Adagrad.html#torch.optim.Adagrad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7575a3f1-39f7-4a95-b548-9b10a2af1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(200, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "701f33d5-7044-42f7-b011-24ae7345b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.1)\n",
    "batch_size = 1000\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92e7903a-a2d9-48f0-8880-85092ed0f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.24908451735973358, validation loss 0.3107801377773285\n",
      "Epoch 1, training loss 0.23656810820102692, validation loss 0.295581191778183\n",
      "Epoch 2, training loss 0.22729599475860596, validation loss 0.28456568717956543\n",
      "\n",
      "ROC AUC: 0.8528349115162229\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    optimizer,\n",
    "                    batch_size,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_val,\n",
    "                    y_val)\n",
    "\n",
    "roc_auc = validation_auc(model, X_val, y_val)\n",
    "print(f\"\\nROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2965e6-aea0-42a4-b7a5-986cdb222b54",
   "metadata": {},
   "source": [
    "## 5.RMSprop\n",
    "\n",
    "RMSprop addresses Adagrad's issue by using a moving average of squared gradients with a decay factor  \n",
    "\n",
    "Pros:\n",
    "- Has advantages of Adagrad and helps address issue of learning rate becoming too small\n",
    "\n",
    "Cons:\n",
    "- Requires tuning of the decay rate hyperparameter  \n",
    "\n",
    "[pytorch documentation](https://pytorch.org/docs/stable/generated/torch.optim.RMSprop.html#torch.optim.RMSprop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "170d298d-d937-4914-bcf5-8b49575bd627",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(200, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b3dae2-53bb-4393-b27d-2cdffd7d15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
    "batch_size = 1000\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "986a413f-4cb0-419e-81bd-cfb65c379019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.25366419553756714, validation loss 0.3046509325504303\n",
      "Epoch 1, training loss 0.23681379854679108, validation loss 0.28540340065956116\n",
      "Epoch 2, training loss 0.22431930899620056, validation loss 0.27185550332069397\n",
      "\n",
      "ROC AUC: 0.8549369228675446\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    optimizer,\n",
    "                    batch_size,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_val,\n",
    "                    y_val)\n",
    "\n",
    "roc_auc = validation_auc(model, X_val, y_val)\n",
    "print(f\"\\nROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b2e8b-d446-4dd4-ac45-2a56b3817b13",
   "metadata": {},
   "source": [
    "## 6.Adam (Adaptive Moment Estimation)\n",
    "\n",
    "Adam combines the benefits of momentum and RMSprop by maintaining both a decaying average of past gradients and a decaying average of past squared gradients  \n",
    "\n",
    "Pros:\n",
    "- Efficient and widely used in practice\n",
    "- Adapts learning rates for each parameter individually  \n",
    "\n",
    "Cons:\n",
    "- May require tuning of hyperparameters\n",
    "\n",
    "[pytorch documentation](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "567f358c-5c54-49d2-aff1-b535ace91634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(200, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "532e1e6a-b12a-4bf4-a00a-afc28fdbc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "batch_size = 1000\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2352c050-37bb-4bf8-bb00-31407546b6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 0.215858593583107, validation loss 0.26923513412475586\n",
      "Epoch 1, training loss 0.19023330509662628, validation loss 0.24331381916999817\n",
      "Epoch 2, training loss 0.1832389533519745, validation loss 0.2415643036365509\n",
      "\n",
      "ROC AUC: 0.8589225826801475\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    optimizer,\n",
    "                    batch_size,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_val,\n",
    "                    y_val)\n",
    "\n",
    "roc_auc = validation_auc(model, X_val, y_val)\n",
    "print(f\"\\nROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a668c53-9975-453b-a3ed-298fc9cdbc23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
